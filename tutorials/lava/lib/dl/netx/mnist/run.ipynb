{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534eb501-a3d6-4871-b989-ecfd3963b9d4",
   "metadata": {},
   "source": [
    "# MNIST Classification\n",
    "\n",
    "This tutorial demonstrates how to use the `lava.lib.dl.netx` API to classify MNIST images, using a `lava.lib.dl.slayer` trained network. The classification is done on both: CPU (via $\\texttt{Loihi2SimCfg}$) and Loihi-2 neuro-cores (via $\\texttt{Loihi2HwCfg}$).\n",
    "\n",
    "Note that this inference tutorial is part of the **end-to-end training** and **evaluation** tutorial: [mnist-on-loihi](https://github.com/R-Gaurav/mnist-on-loihi) -- it contains all the inference code explained here, as well as the `slayer` training code to obtain the trained network-weights (used here). In this tutorial, we will _not_ be training the `slayer` network, rather load the exported (trained) weights via `netx` and do inference on two backends: $\\textsf{Loihi-2 Simulation}$ ($\\texttt{Loihi2SimCfg}$) and $\\textsf{Loihi-2 Hardware}$ ($\\texttt{Loihi2HwCfg}$). The `slayer` training procedure is explained in the [accompanying tutorial](https://r-gaurav.github.io/2024/04/13/Lava-Tutorial-MNIST-Training-on-GPU-and-Evaluation-on-Loihi2.html) and is quite straight-forward. However, there are some tips-and-tricks to keep in mind while evaluating the trained `slayer` network via `netx`; and that's precisely the point of this tutorial. Without further ado, let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236eab5f-912e-4df3-99b4-42c92998957e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7044fd7f-4e92-4cef-908f-676c78ff2afe",
   "metadata": {},
   "source": [
    "# `Process` and `ProcessModel` to encode Images to Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e5261b-519f-4523-880a-42bf21dcfb85",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AbstractProcess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInpImgToSpk\u001b[39;00m(\u001b[43mAbstractProcess\u001b[49m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m  Input process to convert flattened images to binary spikes.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_shape, n_tsteps, curr_img_id, v_thr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AbstractProcess' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "class InpImgToSpk(AbstractProcess):\n",
    "  \"\"\"\n",
    "  Input process to convert flattened images to binary spikes.\n",
    "  \"\"\"\n",
    "  def __init__(self, img_shape, n_tsteps, curr_img_id, v_thr=1):\n",
    "    super().__init__()\n",
    "    self.spk_out = OutPort(shape=(img_shape, ))\n",
    "    self.label_out = OutPort(shape=(1, ))\n",
    "\n",
    "    self.curr_img_id = Var(shape=(1, ), init=curr_img_id)\n",
    "    self.n_ts = Var(shape=(1, ), init=n_tsteps)\n",
    "    self.inp_img = Var(shape=(img_shape, ))\n",
    "    self.ground_truth_label = Var(shape=(1, ))\n",
    "    self.v = Var(shape=(img_shape, ), init=0)\n",
    "    self.vth = Var(shape=(1, ), init=v_thr)\n",
    "\n",
    "@implements(proc=InpImgToSpk, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyInpImgToSpkModel(PyLoihiProcessModel):\n",
    "  \"\"\"\n",
    "  Python implementation for the above `InpImgToSpk` process.\n",
    "  \"\"\"\n",
    "  spk_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "  label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32, precision=32)\n",
    "\n",
    "  curr_img_id: int = LavaPyType(int, int, precision=32)\n",
    "  n_ts: int = LavaPyType(int, int, precision=32)\n",
    "  inp_img: np.ndarray = LavaPyType(np.ndarray, float)\n",
    "  ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "  v: np.ndarray = LavaPyType(np.ndarray, float)\n",
    "  vth: float = LavaPyType(float, float)\n",
    "\n",
    "  def __init__(self, proc_params):\n",
    "    super().__init__(proc_params=proc_params)\n",
    "    self.mnist_dset = MnistDataset()\n",
    "    self.gain = 1\n",
    "    self.bias = 0\n",
    "\n",
    "  def post_guard(self):\n",
    "    \"\"\"\n",
    "    Guard function for post-management phase, necessary to update the next image\n",
    "    index after the current image is processed.\n",
    "\n",
    "    Note: The execution control calls `post_guard()` after `run_spk()` every\n",
    "    time-step, before updating the `self.time_step` variable to next time-step.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 1: # n_ts steps passed, one image processed.\n",
    "      return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def run_post_mgmt(self):\n",
    "    \"\"\"\n",
    "    Post-management phase executed only when the above `post_guard()` returns\n",
    "    True -> then, move to the next image, reset the neuron states, etc.\n",
    "    \"\"\"\n",
    "    img = self.mnist_dset.test_images[self.curr_img_id]\n",
    "    self.inp_img = img/255\n",
    "    self.ground_truth_label = self.mnist_dset.test_labels[self.curr_img_id]\n",
    "    self.label_out.send(np.array([self.ground_truth_label]))\n",
    "    self.v = np.zeros(self.v.shape, dtype=float)\n",
    "    self.curr_img_id += 1\n",
    "\n",
    "  def run_spk(self):\n",
    "    \"\"\"\n",
    "    Spiking phase, this is executed every simulation time-step unconditionally,\n",
    "    and first in order of all the phases.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 1:\n",
    "      self.inp_img = np.zeros(self.inp_img.shape, dtype=float)\n",
    "      self.v = np.zeros(self.v.shape, dtype=float)\n",
    "\n",
    "    J = self.gain*self.inp_img + self.bias\n",
    "    self.v[:] = self.v[:] + J[:]\n",
    "    mask = self.v > self.vth\n",
    "    self.v[mask] = 0\n",
    "    self.spk_out.send(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6b850-71c4-4c1a-8cb8-9b353a09c0bc",
   "metadata": {},
   "source": [
    "# `Process` and `ProcessModel` to infer Classes from Spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1054667c-ecbf-466a-b420-9ee491d844ea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AbstractProcess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mOutSpkToCls\u001b[39;00m(\u001b[43mAbstractProcess\u001b[49m):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m  Output process to collect output neuron spikes and infer predicted class.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m      5\u001b[0m   \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_tsteps, num_test_imgs, n_cls_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, )):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AbstractProcess' is not defined"
     ]
    }
   ],
   "source": [
    "class OutSpkToCls(AbstractProcess):\n",
    "  \"\"\"\n",
    "  Output process to collect output neuron spikes and infer predicted class.\n",
    "  \"\"\"\n",
    "  def __init__(self, n_tsteps, num_test_imgs, n_cls_shape=(10, )):\n",
    "    super().__init__()\n",
    "    self.spikes_in = InPort(shape=n_cls_shape) # Receives output spikes.\n",
    "    self.label_in = InPort(shape=(1, )) # Receives ground truth labels.\n",
    "    self.spikes_accum = Var(shape=n_cls_shape) # Accum. spikes for prediction.\n",
    "    self.n_ts = Var(shape=(1, ), init=n_tsteps) # Image presentation time.\n",
    "    self.pred_labels = Var(shape=(num_test_imgs, ))\n",
    "    self.true_labels = Var(shape=(num_test_imgs, ))\n",
    "\n",
    "@implements(proc=OutSpkToCls, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyOutSpkToClsModel(PyLoihiProcessModel):\n",
    "  spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "  label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)\n",
    "  spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)\n",
    "  n_ts: int = LavaPyType(int, int, precision=32)\n",
    "  pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "  true_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "\n",
    "  def __init__(self, proc_params):\n",
    "    super().__init__(proc_params=proc_params)\n",
    "    self.curr_idx = 0\n",
    "\n",
    "  def post_guard(self):\n",
    "    \"\"\"\n",
    "    Guard function for Post-Management phase.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 0:\n",
    "      return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def run_post_mgmt(self):\n",
    "    \"\"\"\n",
    "    Post-Management phase: executed only when the guard function above returns\n",
    "    True.\n",
    "    \"\"\"\n",
    "    true_label = self.label_in.recv()\n",
    "    pred_label = np.argmax(self.spikes_accum)\n",
    "    self.true_labels[self.curr_idx] = true_label\n",
    "    self.pred_labels[self.curr_idx] = pred_label\n",
    "    self.curr_idx += 1\n",
    "    self.spikes_accum = np.zeros_like(self.spikes_accum)\n",
    "\n",
    "  def run_spk(self):\n",
    "    \"\"\"\n",
    "    Spiking phase: executed unconditionally at every time-step, first in order\n",
    "    among all the phases.\n",
    "    \"\"\"\n",
    "    spk_in = self.spikes_in.recv()\n",
    "    self.spikes_accum = self.spikes_accum + spk_in\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5d3be-7713-4493-b1a5-396da3bdb78a",
   "metadata": {},
   "source": [
    "# Load the `slayer`-trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48f0b6-8982-4913-a410-8d5da47aaa18",
   "metadata": {},
   "source": [
    "# Connecting `Process`es and `netx`-obtained Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73dfa4-bddc-4d29-bd44-a6a919f08313",
   "metadata": {},
   "source": [
    "# Inference on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ffd09-b97c-492a-981b-be18c0b6913a",
   "metadata": {},
   "source": [
    "# Inference on Loihi-2 neuro-cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e97f55-572c-4827-a9fe-98abac813322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
