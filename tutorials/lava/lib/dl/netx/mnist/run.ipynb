{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "534eb501-a3d6-4871-b989-ecfd3963b9d4",
   "metadata": {},
   "source": [
    "# MNIST Classification\n",
    "\n",
    "This tutorial demonstrates how to use the `lava.lib.dl.netx` API to classify MNIST images, using a `lava.lib.dl.slayer` trained network. The classification is done on both: CPU (via $\\texttt{Loihi2SimCfg}$) and Loihi-2 neuro-cores (via $\\texttt{Loihi2HwCfg}$). \n",
    "\n",
    "Note that this inference tutorial is part of the **end-to-end training** and **evaluation** tutorial: [mnist-on-loihi](https://github.com/R-Gaurav/mnist-on-loihi) -- it contains all the inference code explained here, as well as the `slayer` training code to obtain the trained network-weights (used here). In this tutorial, we will _not_ be training the `slayer`-network, rather load the exported (trained) weights via `netx` and do inference on two backends: $\\textsf{Loihi-2 Simulation}$ ($\\texttt{Loihi2SimCfg}$) and $\\textsf{Loihi-2 Hardware}$ ($\\texttt{Loihi2HwCfg}$). The `slayer` training procedure is explained in the [accompanying tutorial](https://r-gaurav.github.io/2024/04/13/Lava-Tutorial-MNIST-Training-on-GPU-and-Evaluation-on-Loihi2.html) and is quite straight-forward. However, there are some tips-and-tricks to keep in mind while evaluating the trained `slayer`-network via `netx`; and that's precisely the point of this tutorial. \n",
    "\n",
    "## `slayer` Network Architecture\n",
    "The architecture of the trained `slayer`-network is as follows: \n",
    "$$\\texttt{Dense CUBA(128)} \\rightarrow \\texttt{Dense CUBA(64)} \\rightarrow \\texttt{Dense CUBA(10)}$$\n",
    "where, `Dense` denotes the fully connected `Dense` connection, and `CUBA(m)` denotes $\\texttt{m}$ Current Based neurons. Note that the first **Hidden** layer: $\\texttt{Dense CUBA(128)}$ accepts $784$-dimensional rate-encoded spikes (of the flattened MNIST images), and the (last) **Output** layer: $\\texttt{Dense CUBA(10)}$ consists of $10$ **Output** neurons denoting the classes; classification is done on the maximally spiking output neuron.\n",
    "\n",
    "## Loihi-2 deployment\n",
    "To deploy and evaluate the above (trained) `slayer`-network on Loihi boards, we are going to load it via `netx` and connect **Input** and **Output** `Process`es (to its ends), which will encode the image to input spikes and predict the class from the output spikes, respectively. Note that since the `slayer`-network is loaded via `netx`, we also call it as <ins>`netx`-obtained network</ins> here (and use the terms interchangeably); the architecture is conceptually going to look like: **Input** `Process` -> `netx`-obtained network -> **Output** `Process`.\n",
    "\n",
    "Without further ado, let's start with inference now and import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a63aef-92a4-48c5-88cb-91a004279f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lava.lib.dl import netx\n",
    "\n",
    "from lava.magma.core.decorator import implements, requires\n",
    "from lava.magma.core.model.py.model import PyLoihiProcessModel\n",
    "from lava.magma.core.model.py.ports import PyInPort, PyOutPort\n",
    "from lava.magma.core.model.py.type import LavaPyType\n",
    "from lava.magma.core.process.ports.ports import InPort, OutPort\n",
    "from lava.magma.core.process.process import AbstractProcess\n",
    "from lava.magma.core.process.variable import Var\n",
    "from lava.magma.core.resources import CPU\n",
    "from lava.magma.core.run_conditions import RunSteps\n",
    "from lava.magma.core.run_configs import Loihi2SimCfg, Loihi2HwCfg\n",
    "from lava.magma.core.sync.protocols.loihi_protocol import LoihiProtocol\n",
    "from lava.utils.dataloader.mnist import MnistDataset\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7044fd7f-4e92-4cef-908f-676c78ff2afe",
   "metadata": {},
   "source": [
    "# `Process` and `ProcessModel` to encode Images to **Input** Spikes\n",
    "As mentioned earlier, the first **Hidden** layer (in the `netx`-obtained network) accepts a $784$-dimensional spike vector corresponding to a flattened MNIST image. Therefore, we need to write down the **Input** `Process` which will rate-encode the pixels to binary spikes; note that while training the above `slayer`-network, the pixels were first normalized between $[0, 1]$ and the rate-encoded via the following equation:\n",
    "$$J = \\alpha<e.x> + \\beta$$\n",
    "where $J$ is the input current to encoding neuron, $e$ is the encoder, $x$ is the normalized pixel value, and $\\alpha$ and $\\beta$ are the neuron's `gain` and `bias` values; their values are $e=1$ (since $x>=0$ always), $\\alpha=1$ and $\\beta=0$. We will use the same above equation (for $J$) to rate-encode the normalized pixel to spikes in our **Input** `Process`: $\\texttt{InpImgToSpk}$ below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dccdbc45-478e-4ece-b513-47d9162fd65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InpImgToSpk(AbstractProcess):\n",
    "  \"\"\"\n",
    "  Input process to convert flattened images to binary spikes.\n",
    "  \"\"\"\n",
    "  def __init__(self, img_shape, n_tsteps, curr_img_id, v_thr=1):\n",
    "    super().__init__()\n",
    "    self.spk_out = OutPort(shape=(img_shape, ))\n",
    "    self.label_out = OutPort(shape=(1, ))\n",
    "\n",
    "    self.curr_img_id = Var(shape=(1, ), init=curr_img_id)\n",
    "    self.n_ts = Var(shape=(1, ), init=n_tsteps)\n",
    "    self.inp_img = Var(shape=(img_shape, ))\n",
    "    self.ground_truth_label = Var(shape=(1, ))\n",
    "    self.v = Var(shape=(img_shape, ), init=0)\n",
    "    self.vth = Var(shape=(1, ), init=v_thr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9985a5c-2153-442d-a6c3-0af5ac302fa1",
   "metadata": {},
   "source": [
    "Now that we have defined the `Process`: $\\texttt{InpImgToSpk}$, let's implement its corresponding `ProcessModel`: $\\texttt{PyInpImgToSpkModel}$ which will run on CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5e5261b-519f-4523-880a-42bf21dcfb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(proc=InpImgToSpk, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyInpImgToSpkModel(PyLoihiProcessModel):\n",
    "  \"\"\"\n",
    "  Python implementation for the above `InpImgToSpk` process.\n",
    "  \"\"\"\n",
    "  spk_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, bool, precision=1)\n",
    "  label_out: PyOutPort = LavaPyType(PyOutPort.VEC_DENSE, np.int32, precision=32)\n",
    "\n",
    "  curr_img_id: int = LavaPyType(int, int, precision=32)\n",
    "  n_ts: int = LavaPyType(int, int, precision=32)\n",
    "  inp_img: np.ndarray = LavaPyType(np.ndarray, float)\n",
    "  ground_truth_label: int = LavaPyType(int, int, precision=32)\n",
    "  v: np.ndarray = LavaPyType(np.ndarray, float)\n",
    "  vth: float = LavaPyType(float, float)\n",
    "\n",
    "  def __init__(self, proc_params):\n",
    "    super().__init__(proc_params=proc_params)\n",
    "    self.mnist_dset = MnistDataset()\n",
    "    self.gain = 1\n",
    "    self.bias = 0\n",
    "\n",
    "  def post_guard(self):\n",
    "    \"\"\"\n",
    "    Guard function for post-management phase, necessary to update the next image\n",
    "    index after the current image is processed.\n",
    "\n",
    "    Note: The execution control calls `post_guard()` after `run_spk()` every\n",
    "    time-step, before updating the `self.time_step` variable to next time-step.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 1: # n_ts steps passed, one image processed.\n",
    "      return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def run_post_mgmt(self):\n",
    "    \"\"\"\n",
    "    Post-management phase executed only when the above `post_guard()` returns\n",
    "    True -> then, move to the next image, reset the neuron states, etc.\n",
    "    \"\"\"\n",
    "    img = self.mnist_dset.test_images[self.curr_img_id]\n",
    "    self.inp_img = img/255\n",
    "    self.ground_truth_label = self.mnist_dset.test_labels[self.curr_img_id]\n",
    "    self.label_out.send(np.array([self.ground_truth_label]))\n",
    "    self.v = np.zeros(self.v.shape, dtype=float)\n",
    "    self.curr_img_id += 1\n",
    "\n",
    "  def run_spk(self):\n",
    "    \"\"\"\n",
    "    Spiking phase, this is executed every simulation time-step unconditionally,\n",
    "    and first in order of all the phases.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 1:\n",
    "      self.inp_img = np.zeros(self.inp_img.shape, dtype=float)\n",
    "      self.v = np.zeros(self.v.shape, dtype=float)\n",
    "\n",
    "    J = self.gain*self.inp_img + self.bias\n",
    "    self.v[:] = self.v[:] + J[:]\n",
    "    mask = self.v > self.vth\n",
    "    self.v[mask] = 0\n",
    "    self.spk_out.send(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ce0eae-0440-4a51-b732-e700d2acb1a8",
   "metadata": {},
   "source": [
    "There are a bunch of important points to note here:\n",
    "* Lava's execution/run `time-step` starts from $1$, and\n",
    "* Whenever the run time-step is one more than a multiple of the image presentation - $\\texttt{self.n\\_ts}$ time-steps (per-image):\n",
    "    * The $\\texttt{run\\_spk()}$ phase resets the input image variable: $\\texttt{self.inp\\_img}$ and the encoding neuron's voltage: $\\texttt{self.v}$ to all zeros, and\n",
    "    * The $\\texttt{post\\_guard()}$ phase returns $\\texttt{True}$ and the $\\texttt{run\\_post\\_mgmt()}$ phase gets called, which also resets the necessary variables\n",
    "\n",
    "Let's look into these phases' operations more closely; note that they are discussed in considerable details (on a per time-step basis) in the [accompanying tutorial](https://r-gaurav.github.io/2024/04/13/Lava-Tutorial-MNIST-Training-on-GPU-and-Evaluation-on-Loihi2.html). \n",
    "\n",
    "As you would know, in each time-step, the $\\texttt{run\\_spk()}$ phase is the first phase to be executed among $\\texttt{post\\_guard()}$ and $\\texttt{run\\_post\\_mgmt()}$ phases. Therefore, when the $\\texttt{InpImgToSpk}$ `Process`'s execution starts, the $\\texttt{self.inp\\_img}$ and $\\texttt{self.v}$ are reset to all zeros in $\\texttt{run\\_spk()}$, and since $\\texttt{post\\_guard()}$ returns $\\texttt{True}$, the $\\texttt{run\\_post\\_mgmt()}$ phase updates $\\texttt{self.inp\\_img}$ (and related variables). In the subsequent time-steps $\\texttt{run\\_spk()}$ keeps getting called and the rate-encoding of $\\texttt{self.inp\\_img}$ progresses.\n",
    "\n",
    "When the per-image presentation time-steps (i.e., $\\texttt{self.n\\_ts}$) are over, i.e., in the $(\\texttt{self.n\\_ts} + 1)^{\\text{th}}$ time-step, $\\texttt{run\\_spk()}$ is called gain, but note that $\\texttt{self.inp\\_img}$ is still the previous old image, therefore, it's important to reset the $\\texttt{self.inp\\_img}$ and $\\texttt{self.v}$ in $\\texttt{run\\_spk()}$ to ensure that the previous old image does _not_ corrupt the prediction corresponding to the new (to be updated) image. In the same $(\\texttt{self.n\\_ts} + 1)^{\\text{th}}$ time-step, $\\texttt{post\\_guard()}$ returns $\\texttt{True}$ and the $\\texttt{run\\_post\\_mgmt()}$ phase finally updates $\\texttt{self.inp\\_img}$ to the next new image (along with updating the ground truth).\n",
    "\n",
    "Thus, it is important to reset $\\texttt{self.inp\\_img}$ and $\\texttt{self.v}$ in the $\\texttt{run\\_spk()}$ phase in every $(k\\times\\texttt{self.n\\_ts} + 1)^{\\text{th}}$ time-step, where $k \\in \\mathbb{W}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6b850-71c4-4c1a-8cb8-9b353a09c0bc",
   "metadata": {},
   "source": [
    "# `Process` and `ProcessModel` to infer Classes from **Output** Spikes\n",
    "As mentioned before, the **Output** layer -- composed of $10$ neurons (each denoting a class) in the `netx`-obtained network produces spikes, upon which we can infer classes by accumulating them over a period of $\\texttt{self.n\\_ts}$ time-steps (for each image) and reporting the index which has the maximum number of accumulated spikes. To do the same, we write down the following **Output** `Process`: $\\texttt{OutSpkToCls}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818d6fbb-9c0e-4802-843b-c589339743b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutSpkToCls(AbstractProcess):\n",
    "  \"\"\"\n",
    "  Output process to collect output neuron spikes and infer predicted class.\n",
    "  \"\"\"\n",
    "  def __init__(self, n_tsteps, num_test_imgs, n_cls_shape=(10, )):\n",
    "    super().__init__()\n",
    "    self.spikes_in = InPort(shape=n_cls_shape) # Receives output spikes.\n",
    "    self.label_in = InPort(shape=(1, )) # Receives ground truth labels.\n",
    "    self.spikes_accum = Var(shape=n_cls_shape) # Accum. spikes for prediction.\n",
    "    self.n_ts = Var(shape=(1, ), init=n_tsteps) # Image presentation time.\n",
    "    self.pred_labels = Var(shape=(num_test_imgs, ))\n",
    "    self.true_labels = Var(shape=(num_test_imgs, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630a4c2e-a974-4438-8060-683869ed0035",
   "metadata": {},
   "source": [
    "Now that we have the $\\texttt{OutSpkToCls}$ `Process` ready, let's write down its corresponding `ProcessModel`: $\\texttt{PyOutSpkToClsModel}$ which also runs on CPU. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1054667c-ecbf-466a-b420-9ee491d844ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "@implements(proc=OutSpkToCls, protocol=LoihiProtocol)\n",
    "@requires(CPU)\n",
    "class PyOutSpkToClsModel(PyLoihiProcessModel):\n",
    "  spikes_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, bool, precision=1)\n",
    "  label_in: PyInPort = LavaPyType(PyInPort.VEC_DENSE, int, precision=32)\n",
    "  spikes_accum: np.ndarray = LavaPyType(np.ndarray, np.int32, precision=32)\n",
    "  n_ts: int = LavaPyType(int, int, precision=32)\n",
    "  pred_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "  true_labels: np.ndarray = LavaPyType(np.ndarray, int, precision=32)\n",
    "\n",
    "  def __init__(self, proc_params):\n",
    "    super().__init__(proc_params=proc_params)\n",
    "    self.curr_idx = 0\n",
    "\n",
    "  def post_guard(self):\n",
    "    \"\"\"\n",
    "    Guard function for Post-Management phase.\n",
    "    \"\"\"\n",
    "    if self.time_step % self.n_ts == 0:\n",
    "      return True\n",
    "\n",
    "    return False\n",
    "\n",
    "  def run_post_mgmt(self):\n",
    "    \"\"\"\n",
    "    Post-Management phase: executed only when the guard function above returns\n",
    "    True.\n",
    "    \"\"\"\n",
    "    true_label = self.label_in.recv()\n",
    "    pred_label = np.argmax(self.spikes_accum)\n",
    "    self.true_labels[self.curr_idx] = true_label\n",
    "    self.pred_labels[self.curr_idx] = pred_label\n",
    "    self.curr_idx += 1\n",
    "    self.spikes_accum = np.zeros_like(self.spikes_accum)\n",
    "\n",
    "  def run_spk(self):\n",
    "    \"\"\"\n",
    "    Spiking phase: executed unconditionally at every time-step, first in order\n",
    "    among all the phases.\n",
    "    \"\"\"\n",
    "    spk_in = self.spikes_in.recv()\n",
    "    self.spikes_accum = self.spikes_accum + spk_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32f0587-1d74-49c8-807f-00ac4bfd0326",
   "metadata": {},
   "source": [
    "As can be seen above, the $\\texttt{post\\_guard()}$ phase returns $\\texttt{True}$ in every $(k\\times\\texttt{self.n\\_ts})^{\\text{th}}$ time-step, where $k\\in\\mathbb{W}$, and thus, the $\\texttt{run\\_post\\_mgmt()$ phase gets evaluated in the very same time-step. Let's look into the operation of these phases more closely; per time-step operation details can be found in the [accompanying tutorial](https://r-gaurav.github.io/2024/04/13/Lava-Tutorial-MNIST-Training-on-GPU-and-Evaluation-on-Loihi2.html).\n",
    "\n",
    "As you already know, the Lava run time-step starts with $1$ and $\\texttt{run\\_spk()}$ is the first phase to be called every time-step in a `Process`'s execution. Here, in the $1^{\\text{st}}$ time-step, the $\\texttt{run\\_spk()}$ phase is called first and it accumulates the incoming spikes from the **Output** layer of the `netx`-obtained network; $\\texttt{post\\_guard()}$ returns $\\texttt{False}$ and $\\texttt{run\\_post\\_mgmt()}$ is _not_ called. Such processing continues until the $\\texttt{self.n\\_ts}^{\\text{th}}$ time-step arrives. In the time-step $=\\texttt{self.n\\_ts}$, $\\texttt{run\\_spk()}$ still accumulates the output spikes corresponding to the first input image, post which, $\\texttt{post\\_guard()}$ returns $\\texttt{True}$ and $\\texttt{run\\_post\\_mgmt()}$ subsequently computes the index of the maximally spiking neuron as the predicted class (other variables are accordingly reset or updated). \n",
    "\n",
    "For the next time-steps, i.e., $(\\texttt{self.n\\_ts} + 1)^{\\text{th}}$ onwards, the execution of $\\texttt{OutSpkToCls}$ `Process` continues as explained above, but with the updated $\\texttt{self.inp\\_img}$ in the $\\texttt{InpImgToSpk}$ `Process`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df5d3be-7713-4493-b1a5-396da3bdb78a",
   "metadata": {},
   "source": [
    "# Load the `slayer`-trained weights\n",
    "\n",
    "Now that both the **Input** and **Output** `Process`es are ready, we can proceed with loading the (trained) `slayer`-network via `netx`. However, before we do that, note that the `slayer`-network was trained for $20$ time-steps each, on MNIST training images. Therefore, the test-image presentation time-steps, i.e., $\\texttt{self.n_ts}$ should be $20$ time-steps during inference as well. In the code below, $\\texttt{n_tsteps}$ denotes the test-image presentation time-steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46eaf699-548e-41ec-88d8-b156ddc7c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `n_tsteps` is the presentation time-steps of each test-image.\n",
    "n_tsteps = 20 \n",
    "#n_tsteps = 32\n",
    "\n",
    "net = netx.hdf5.Network(\n",
    "    net_config=\"./trained_mnist_network.net\", # Trained network path.\n",
    "    reset_interval=n_tsteps, # Presentation time-steps of each test-image.\n",
    "    reset_offset=1 # Phase shift / offset time-step to reset this network.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582b09d7-78e4-4e9d-88a8-87d8d8883e0e",
   "metadata": {},
   "source": [
    "Note the two important nuances above:\n",
    "* $\\texttt{reset\\_interval}$ is set equal to $\\texttt{n\\_tsteps}$, which implies that the `netx`-obtained network is reset after every $\\texttt{n\\_tsteps}$ time-steps, however\n",
    "* $\\texttt{reset\\_offset}$ is set equal to $1$, which implies that the network is reset with a phase shift of $1$ time-step (an important detail here)\n",
    "\n",
    "In other words, $\\texttt{reset_offset}=1$ implies that the count of $\\texttt{reset_interval}=\\texttt{n_tsteps}$ starts after the time-step $1$ is over. That is, in the above cell's code, if $\\texttt{n_tsteps}=20$, then the `netx`-obtained network: $\\texttt{net}$ is reset after $21^{\\text{st}}, 41^{\\text{st}}, 61^{\\text{st}}, \\cdots$ time-steps. \n",
    "\n",
    "Cool! Building all the fundamental components to deploy our `slayer`-network on Loihi is done now; except that we still need adapters to transfer spikes to-and-fro between the CPU and the Loihi neuro-cores. Those adapters are straightforward to understand and are already written in the $\\texttt{utils.py}$ file in this current directory. We next import the"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f48f0b6-8982-4913-a410-8d5da47aaa18",
   "metadata": {},
   "source": [
    "# Connecting `Process`es and `netx`-obtained Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec73dfa4-bddc-4d29-bd44-a6a919f08313",
   "metadata": {},
   "source": [
    "# Inference on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9ffd09-b97c-492a-981b-be18c0b6913a",
   "metadata": {},
   "source": [
    "# Inference on Loihi-2 neuro-cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e97f55-572c-4827-a9fe-98abac813322",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
